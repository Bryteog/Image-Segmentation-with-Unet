{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from Constants import *\n",
    "import outputs\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 2\n",
    "image = imageio.imread(image_list[num_samples])\n",
    "mask = imageio.imread(mask_list[num_samples])\n",
    "\n",
    "figure, arrar = plt.subplots(1, 2, figsize = (10, 8))\n",
    "plt.axis(\"off\")\n",
    "array[0].imshow(image)\n",
    "array[0].set_title(\"Image\")\n",
    "array[1].imshow(mask[:, :, 0])\n",
    "array[1].set_title(\"Segmented image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dataset = tf.data.Dataset.list_files(image_list, shuffle = False)\n",
    "mask_dataset = tf.data.Dataset.list_files(mask_list, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files = tf.constant(image_list)\n",
    "mask_files = tf.constant(mask_list)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((image_files, mask_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_path(image_path, mask_path):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_png(image, channels = 3)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    \n",
    "    mask = tf.io.read_file(mask_path)\n",
    "    mask = tf.image.decode_png(mask, channels = 3)\n",
    "    mask = tf.math.reduce_max(mask, axis =- 1, keepdims = True)\n",
    "    \n",
    "    return image, mask\n",
    "\n",
    "\n",
    "def image_preprocessing(image, mask):\n",
    "    image = tf.image.resize(image, (96, 128), method = 'nearest')\n",
    "    mask = tf.image.resize(mask, (96, 128), method = 'nearest')\n",
    "    image = image / 255.\n",
    "    \n",
    "    return image, mask\n",
    "\n",
    "image_dataset = dataset.map(preprocessing_path)\n",
    "processed_images = image_dataset(image_preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unet Model\n",
    "\n",
    "def conv_block(inputs = None, NUM_FILTERS, dropout = 0, max_pooling = True):\n",
    "    \n",
    "    conv = layers.Conv2D(NUM_FILTERS, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv = layers.Conv2D(NUM_FILTERS, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv)\n",
    "    \n",
    "    if dropout_prob > 0:\n",
    "        conv = layers.Dropout(dropout_prob)(conv)\n",
    "        \n",
    "    if max_pooling2D:\n",
    "        next_layer = layers.MaxPooling2D(pool_size = (2, 2))(conv)\n",
    "    else:\n",
    "        next_layer = conv\n",
    "        \n",
    "    skip_connection = conv\n",
    "    \n",
    "    return next_layer, skip_connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = (96, 128, 3)\n",
    "inputs = layers.Input(INPUT_SHAPE)\n",
    "\n",
    "conv_block1 = conv_block(inputs, NUM_FILTERS * 1)\n",
    "model_1 = keras.Model(inputs = inputs, outputs = conv_block1)\n",
    "\n",
    "output_1 = [['InputLayer', [(None, 96, 128, 3)], 0],\n",
    "           ['Conv2D', (None, 96, 128, 32), 896, 'same', 'relu', 'HeNormal'],\n",
    "           ['Conv2D', (None, 96, 128, 32), 9248, 'same', 'relu', 'HeNormal'],\n",
    "           ['MaxPooling2D', (None, 48, 64, 32), 0, (2, 2)]]\n",
    "\n",
    "output_2 = [['InputLayer', [(None, 96, 128, 3)], 0],\n",
    "           ['Conv2D', (None, 96, 128, 1024), 28672, 'same', 'relu', 'HeNormal'],\n",
    "           ['Conv2D', (None, 96, 128, 1024), 9438208, 'same', 'relu', 'HeNormal'],\n",
    "           ['Dropout', (None, 96, 128, 1024), 0, 0.1],\n",
    "           ['MaxPooling2D', (None, 48, 64, 1024), 0, (2, 2)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsampling_block(expansive_input, contractive_input, NUM_FILTERS):\n",
    "    \n",
    "    upsample = layers.Conv2DTranspose(NUM_FILTERS, 3, strides = 2, padding = 'same')(expansive_input)\n",
    "    merge = layers.Concatenate([upsample, contractive_input], axis = 3)\n",
    "    \n",
    "    conv = layers.Conv2D(NUM_FILTERS, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge)\n",
    "    conv = layers.Conv2D(NUM_FILTERS, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv)\n",
    "    \n",
    "    return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE_1 = (12, 16, 256)\n",
    "INPUT_SHAPE_2 = (24, 32, 128)\n",
    "\n",
    "expansive_inputs = layers.Input(INPUT_SHAPE_1)\n",
    "contractive_inputs = layers.Input(INPUT_SHAPE_2)\n",
    "\n",
    "conv_block1 = upsampling_block(expansive_inputs, contractive_inputs, NUM_FILTERS * 1)\n",
    "model_1 = keras.Model(inputs = [expansive_inputs, contractive_inputs], outputs = conv_block1)\n",
    "\n",
    "output_1 = [['InputLayer', [(None, 12, 16, 256)], 0],\n",
    "           ['Conv2DTranspose', (None, 24, 32, 32), 73760],\n",
    "           ['InputLayer', (None, 24, 32, 128), 0],\n",
    "           ['Concatenate', (None, 24, 32, 160), 0],\n",
    "           ['Conv2D', (None, 24, 32, 32), 46112, 'same', 'relu', 'HeNormal'],\n",
    "           ['Conv2D', (None, 24, 32, 32), 9248, 'same', 'relu', 'HeNormal']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Unet_model(input_size = (96, 128, 3), NUM_FILTERS, NUM_CLASSES = 23):\n",
    "    \n",
    "    # Encoding block\n",
    "    inputs = layers.Input(input_size)\n",
    "    conv_block1 = conv_block(inputs, NUM_FILTERS)\n",
    "    conv_block2 = conv_block(conv_block1[0], NUM_FILTERS * 2)\n",
    "    conv_block3 = conv_block(conv_block2[0], NUM_FILTERS * 4)\n",
    "    conv_block4 = conv_block(conv_block3[0], NUM_FILTERS * 8, dropout_prob = 0.3)\n",
    "    conv_block5 = conv_block(conv_block4[0], NUM_FILTERS * 16, dropout_prob = 0.3, max_pooling = False)\n",
    "    \n",
    "    # Decoding block\n",
    "    upsampling_block1 = upsampling_block(conv_block5[0], conv_block4[1], NUM_FILTERS * 8)\n",
    "    upsampling_block2 = upsampling_block(upsampling_block1, conv_block3[1], NUM_FILTERS * 4)\n",
    "    upsampling_block3 = upsampling_block(upsampling_block2, conv_block2[1], NUM_FILTERS * 2)\n",
    "    upsampling_block4 = upsampling_block(upsampling_block3, conv_block1[1], NUM_FILTERS)\n",
    "    \n",
    "    conv_block6 = layers.Conv2D(NUM_FILTERS, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(upsampling_block4)\n",
    "    conv_block7 = layers.Conv2(NUM_CLASSES, 1, padding = 'same')(conv_block6)\n",
    "    \n",
    "    model = keras.Model(inputs = inputs, output = conv_block7)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_model = Unet_model((IMAGE_HEIGHT, IMAGE_WIDTH, NUM_CHANNELS))\n",
    "unet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_model.compile(optimizer = 'adam', \n",
    "                   loss = keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
    "                   metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(display_list):\n",
    "    \n",
    "    plt.figure(figsize = (12, 12))\n",
    "    title = [\"Input Image\", \"True Mask\", \"Predicted Mask\"]\n",
    "    \n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i + 1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(keras.preprocessing.image.array_to_img(display_list[i]))\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, mask in image_dataset.take(1):\n",
    "    sample_image, sample_mask = imahe, mask\n",
    "    print(mask.shape)\n",
    "display([sample_image, sample_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, mask in processed_images.take(1):\n",
    "    sample_image, sample_mask = imahe, mask\n",
    "    print(mask.shape)\n",
    "display([sample_image, sample_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_images.batch(BATCH_SIZE)\n",
    "train_set = processed_images.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = unet_model.fit(train_set,\n",
    "                         epochs = EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plt(history.history['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mask(predicted_mask):\n",
    "    predicted_mask = tf.argmax(predicted_mask, axis =- 1)\n",
    "    predicted_mask = predicted_mask[..., tf.newaxis]\n",
    "    \n",
    "    return predicted_mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_prediction(dataset = None, num = 1):\n",
    "    \n",
    "    if dataset:\n",
    "        for image, mask in dataset.take(num):\n",
    "            predicted_mask = unet_model.predict(image)\n",
    "            display([image[0], mask[0], make_mask(predicted_mask)])\n",
    "    else:\n",
    "        display([sample_image,\n",
    "                 sample_mask,\n",
    "                 make_mask(unet_model.predict(sample_image[tf.newaxis, ...]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_prediction(train_set, 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
